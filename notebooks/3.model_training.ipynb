{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Embedding, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from src.image_sharing_plateform.constants import *\n",
    "\n",
    "from src.image_sharing_plateform.components.data_generator import ImageCaptionGenerator\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating vocab size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = Path(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\processed\\training_data.txt\")  # Convert to Path object\n",
    "\n",
    "# with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# unique_words = []\n",
    "# caption_lengths = []\n",
    "# datas = text.split(\"\\n\")\n",
    "# for data in datas:\n",
    "#     s = data.split(\"\\t\")[1]\n",
    "#     s.split(\" \")\n",
    "#     s1 = s.split(\" \")\n",
    "#     unique_words = unique_words + s1[1:-1]\n",
    "\n",
    "# print(len(unique_words))\n",
    "# print(len(set(unique_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vgg output feature shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\processed\\extracted_features.p\", \"rb\") as file:\n",
    "    feature_data = pickle.load(file)\n",
    "\n",
    "print(list(feature_data.values())[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating max seq length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\processed\\training_data.txt\")  # Convert to Path object\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "caption_lengths = []\n",
    "datas = text.split(\"\\n\")\n",
    "for data in datas:\n",
    "    s = data.split(\"\\t\")[1]\n",
    "    s1 = s.split(\" \")[1:-1]\n",
    "    caption_lengths.append(len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(caption_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # caption_lengths = [len(cap.split()) for caps in train_captions.values() for cap in caps]\n",
    "# SEQ_LENGTH = int(np.percentile(caption_lengths, 95))  # Choose 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_length = np.mean(caption_lengths)\n",
    "# std_length = np.std(caption_lengths)\n",
    "# SEQ_LENGTH = int(mean_length + std_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_namespace(d):\n",
    "    \"\"\"Recursively converts a dictionary into a SimpleNamespace object.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(path_to_yaml: Path):\n",
    "    try:\n",
    "        with open(path_to_yaml, \"r\") as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            return dict_to_namespace(content)  # Convert dict to namespace\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path_to_yaml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    train_data_path : Path\n",
    "    validation_data_path : Path\n",
    "    trained_model_path : Path\n",
    "    history_path : Path\n",
    "    CreateSqueezeModel_config: dict\n",
    "    CreateLSTMSequence_config: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainingConfigurationManager:\n",
    "    def __init__(self,config_filepath):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "    \n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        model_training_data_config = self.config.model_training\n",
    "\n",
    "        create_directories([model_training_data_config.trained_model_path, model_training_data_config.history_path])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            train_data_path = model_training_data_config.train_data_path,\n",
    "\n",
    "            validation_data_path = model_training_data_config.validation_data_path,\n",
    "            \n",
    "            trained_model_path = model_training_data_config.trained_model_path,\n",
    "\n",
    "            history_path = model_training_data_config.history_path,\n",
    "            \n",
    "            CreateSqueezeModel_config = self.config.CreateSqueezeModel_config,\n",
    "\n",
    "            CreateLSTMSequence_config = self.config.CreateLSTMSequence_config\n",
    "\n",
    "        )\n",
    "        \n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CreateSqueezeModel(keras.Model):\n",
    "#     def __init__(self,dropout,activation):\n",
    "#         super().__init__()\n",
    "#         \"\"\"CNN features squeezed from 512 to 256\"\"\"\n",
    "#         self.fe1 = Dropout(dropout)\n",
    "#         self.fe2 = Dense(256, activation=activation)\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         x = self.fe1(inputs, training=training)\n",
    "#         x = self.fe2(x)\n",
    "#         return x\n",
    "    \n",
    "# class CreateLSTMSequence(keras.Model):\n",
    "#     def __init__(self, vocab_size):\n",
    "#         super().__init__()\n",
    "#         \"\"\"LSTM sequence model\"\"\"\n",
    "#         self.embedding = Embedding(vocab_size, 256, mask_zero=True)\n",
    "#         self.drp = Dropout(0.5)\n",
    "#         self.lstm = LSTM(256)\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         x = self.embedding(inputs)\n",
    "#         x = self.drp(x, training=training)\n",
    "#         x = self.lstm(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Input, Add\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "class CreateSqueezeModel(keras.Model):\n",
    "    def __init__(self, dropout, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fe1 = Dropout(dropout)\n",
    "        self.fe2 = Dense(256, activation=activation)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.fe1(inputs, training=training)\n",
    "        x = self.fe2(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"dropout\": self.fe1.rate,\n",
    "            \"activation\": self.fe2.activation.__name__,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "class CreateLSTMSequence(keras.Model):\n",
    "    def __init__(self, vocab_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding = Embedding(vocab_size, 256, mask_zero=True)\n",
    "        self.drp = Dropout(0.5)\n",
    "        self.lstm = LSTM(256)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.drp(x, training=training)\n",
    "        x = self.lstm(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"vocab_size\": self.embedding.input_dim})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class ImageSharingModel:\n",
    "    def __init__(self, trained_model_path,history_path,CreateSqueezeModel_config, CreateLSTMSequence_config):\n",
    "        \n",
    "        \"\"\"\n",
    "        Custom Data Generator for Image Captioning using RNN/LSTM.\n",
    "        \"\"\"\n",
    "        self.trained_model_path = trained_model_path\n",
    "        self.history_path = history_path\n",
    "        self.CreateSqueezeModel_config = CreateSqueezeModel_config\n",
    "        self.CreateLSTMSequence_config = CreateLSTMSequence_config\n",
    "    \n",
    "\n",
    "    def save_trained_model_history(self,model, history):\n",
    "        os.makedirs(self.trained_model_path, exist_ok=True)\n",
    "        \n",
    "        model.save(os.path.join(self.trained_model_path, \"trained_model.h5\"))\n",
    "        \n",
    "        \n",
    "        with open(os.path.join(self.history_path, \"history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # print(f\"Model saved at {os.path.join(self.trained_model_path, 'trained_model.h5')}\")\n",
    "\n",
    "\n",
    "    def create_image_captioning_model(self):\n",
    "        inputs1 = Input(shape=(self.CreateSqueezeModel_config.input_shape,))\n",
    "        \n",
    "        squeeze_model = CreateSqueezeModel(self.CreateSqueezeModel_config.dropout,\n",
    "                                           self.CreateSqueezeModel_config.activation)\n",
    "        \n",
    "        fe2 = squeeze_model(inputs1)\n",
    "\n",
    "        inputs2 = Input(shape=(self.CreateLSTMSequence_config.input_length_lstm,))\n",
    "        \n",
    "        lstm_model = CreateLSTMSequence(self.CreateLSTMSequence_config.vocab_size)\n",
    "        \n",
    "        se3 = lstm_model(inputs2)\n",
    "\n",
    "        decoder1 = Add()([fe2, se3])\n",
    "        decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "        outputs = Dense(self.CreateLSTMSequence_config.vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "        model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "        model.compile(loss=self.CreateLSTMSequence_config.loss, optimizer=self.CreateLSTMSequence_config.optimizer)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def start_model_training(self,model, train_data_generator, validation_data_generator):\n",
    "        steps_per_epoch = len(train_data_generator)\n",
    "        validation_steps = len(validation_data_generator)\n",
    "\n",
    "        # Train the model and store the history\n",
    "\n",
    "        history = model.fit(\n",
    "                train_data_generator,\n",
    "                epochs=1,  # Adjust based on your needs\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_data=validation_data_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                verbose=1\n",
    "                )\n",
    "\n",
    "        self.save_trained_model_history(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    try:\n",
    "        manager = ModelTrainingConfigurationManager(PARAMS_FILE_PATH)\n",
    "        model_training_config = manager.get_model_training_config()\n",
    "    \n",
    "        # # # # Access attributes\n",
    "        train_data_path = model_training_config.train_data_path\n",
    "        validation_data_path = model_training_config.validation_data_path\n",
    "        trained_model_path = model_training_config.trained_model_path\n",
    "        history_path = model_training_config.history_path\n",
    "\n",
    "        with open(train_data_path + \"/\" + \"train_data.pkl\", \"rb\") as file:\n",
    "            train_data = pickle.load(file)\n",
    "            print(train_data.keys())\n",
    "\n",
    "        with open(validation_data_path + \"/\" + \"validation_data.pkl\", \"rb\") as file:\n",
    "            validation_data = pickle.load(file)\n",
    "\n",
    "        train_data_features = train_data[\"image_data\"]\n",
    "        train_caption_tokenized = train_data[\"caption_data\"]\n",
    "\n",
    "        validation_data_features = validation_data[\"image_data\"]\n",
    "        validation_caption_tokenized = validation_data[\"caption_data\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    \n",
    "    train_data_generator = ImageCaptionGenerator(\n",
    "        image_features = train_data_features , \n",
    "        tokenized_captions = train_caption_tokenized, \n",
    "        batch_size = 8 , \n",
    "        shuffle=True)\n",
    "    \n",
    "\n",
    "    validation_data_generator = ImageCaptionGenerator(\n",
    "        image_features = validation_data_features , \n",
    "        tokenized_captions = validation_caption_tokenized , \n",
    "        batch_size=10 , \n",
    "        shuffle=True)\n",
    "    \n",
    "\n",
    "    model_training = ImageSharingModel(\n",
    "        model_training_config.trained_model_path, \n",
    "        model_training_config.history_path,\n",
    "        model_training_config.CreateSqueezeModel_config, \n",
    "        model_training_config.CreateLSTMSequence_config)\n",
    "    \n",
    "    \n",
    "    model = model_training.create_image_captioning_model()\n",
    "    \n",
    "\n",
    "    model_training.start_model_training(\n",
    "        model, \n",
    "        train_data_generator, \n",
    "        validation_data_generator)\n",
    "\n",
    "except Exception as e:\n",
    "        # logger.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True,show_dtype=True,show_layer_names=True, show_layer_activations=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------- Work in future----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data_generator.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_data_generator:\n",
    "#     (X1_batch, X2_batch), y_batch = batch\n",
    "#     print(f\"X1_batch shape: {X1_batch.shape}\")  # Should be (batch_size, 256)\n",
    "#     print(f\"X2_batch shape: {X2_batch.shape}\")  # Should be (batch_size, 32)\n",
    "#     print(f\"y_batch shape: {y_batch.shape}\")    # Should be (batch_size,)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# @tf.function\n",
    "# def train_step(x_batch, y_batch, model, optimizer, loss_fn):\n",
    "#     \"\"\"Single training step with Graph Mode enabled.\"\"\"\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         y_pred = model(x_batch, training=True)\n",
    "#         loss = loss_fn(y_batch, y_pred)\n",
    "    \n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "#     return loss\n",
    "\n",
    "# @tf.function\n",
    "# def validation_step(x_batch, y_batch, model, loss_fn):\n",
    "#     \"\"\"Single validation step (no weight updates).\"\"\"\n",
    "#     y_pred = model(x_batch, training=False)  # Forward pass (no training)\n",
    "#     loss = loss_fn(y_batch, y_pred)  # Compute validation loss\n",
    "#     return loss\n",
    "\n",
    "# # Training loop with validation\n",
    "# num_epochs = 2  # Adjust epochs\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Training phase\n",
    "#     train_losses = []\n",
    "#     for i in range(len(train_data_generator)):\n",
    "#         x_batch, y_batch = train_data_generator[i]\n",
    "#         loss = train_step(x_batch, y_batch, model, optimizer, loss_fn)\n",
    "#         train_losses.append(loss)\n",
    "    \n",
    "#     # Compute average training loss\n",
    "#     avg_train_loss = tf.reduce_mean(train_losses).numpy()\n",
    "\n",
    "#     # Validation phase\n",
    "#     val_losses = []\n",
    "#     for i in range(len(validation_data_generator)):  # Iterate over validation data\n",
    "#         x_val, y_val = validation_data_generator[i]\n",
    "#         val_loss = validation_step(x_val, y_val, model, loss_fn)\n",
    "#         val_losses.append(val_loss)\n",
    "\n",
    "#     # Compute average validation loss\n",
    "#     avg_val_loss = tf.reduce_mean(val_losses).numpy()\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"temp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model(r\"U:\\nlp_project\\Image_Sharing_Plateform\\temp_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(filename):\n",
    "       \n",
    "#         # Load VGG16 model without top layers\n",
    "#         base_model = VGG16(input_shape=(500, 500, 3), \n",
    "#                            include_top=False, weights='imagenet')\n",
    "\n",
    "#         model = tf.keras.Sequential([\n",
    "#             base_model,\n",
    "#             GlobalAveragePooling2D()  # Converts spatial dimensions to (batch_size, 512)\n",
    "#         ])\n",
    "\n",
    "#         # features = {}\n",
    "        \n",
    "#         image = Image.open(filename)\n",
    "#         image = image.resize((500,500))\n",
    "#         image = np.array(image) / 255.0  # Normalize correctly\n",
    "#         image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "            \n",
    "#         # Extract feature and flatten it\n",
    "#         feature = model.predict(image)  # Shape: (1, 512)\n",
    "        \n",
    "#         return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_feature = extract_features(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\row\\Flickr8k_Dataset\\Flicker8k_Dataset\\3672940355_47f30e2b28.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the model containing the TextVectorization layer\n",
    "# loaded_model = load_model(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\processed\\vectorizer\")\n",
    "\n",
    "# # Extract the TextVectorization layer\n",
    "# vocab = loaded_model.layers[0].get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = vectorizer(tf.convert_to_tensor([\"<start>\"]))\n",
    "# print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def generate_caption(model, image_feature, vectorizer):\n",
    "#     \"\"\"Generate a caption for the given image feature vector.\"\"\"\n",
    "\n",
    "#     # sequence = vectorizer([\"<start>\"])  # Convert \"<start>\" to tensor\n",
    "#     # sequence = tf.convert_to_tensor(vectorizer([\"<start>\"]), dtype=tf.int32)\n",
    "    \n",
    "#     start_token = vectorizer(tf.constant([\"<start>\"]))  \n",
    "#     sequence = tf.cast(start_token, tf.int32)\n",
    "#     # print(sequence)\n",
    "\n",
    "#     caption = []\n",
    "\n",
    "#     for _ in range(15):\n",
    "#         sequence_padded = pad_sequences([sequence], maxlen=32, padding='post')\n",
    "#         print(\"Sequence Padded Shape1:\", sequence_padded.shape)\n",
    "    \n",
    "#         y_pred = model([image_feature, sequence_padded], verbose=1)\n",
    "#         predicted_index = np.argmax(y_pred)\n",
    "\n",
    "#         if predicted_index == vectorizer('<end>').numpy()[0]:  # Stop if \"<end>\" token is generated\n",
    "#             break\n",
    "\n",
    "#         caption.append(predicted_index)\n",
    "#         sequence = np.append(sequence, predicted_index)[-15:]  # Update sequence\n",
    "    \n",
    "\n",
    "#     # vocab = vectorizer.get_vocabulary()\n",
    "#     vocab = vectorizer.layers[0].get_vocabulary()\n",
    "#     final_caption = \" \".join(vocab[idx] for idx in caption)\n",
    "\n",
    "#     return final_caption\n",
    "\n",
    "# generate_caption(model, extracted_feature, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# @tf.function\n",
    "# def generate_caption(model, image_feature, vectorizer):\n",
    "#     \"\"\"Generate a caption for the given image feature vector.\"\"\"\n",
    "\n",
    "#     # start_token = vectorizer(tf.constant([\"<start>\"]))  \n",
    "#     # sequence = tf.cast(start_token, tf.int32)  # Ensure it is int32\n",
    "\n",
    "#     start_token = vectorizer(tf.constant([\"<start>\"]))  \n",
    "#     sequence = tf.cast(start_token, tf.int32)  # Ensure it is int32\n",
    "#     sequence = tf.reshape(sequence, [-1])  # Ensure it's 1D\n",
    "\n",
    "\n",
    "#     caption = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "\n",
    "#     for i in tf.range(15):  # Use tf.range for graph mode compatibility\n",
    "#         # Ensure sequence is expanded correctly\n",
    "#         # sequence_padded = pad_sequences([sequence], maxlen=32, padding='post')\n",
    "        \n",
    "#         sequence_padded = tf.pad(sequence, [[0, 32 - tf.shape(sequence)[0]]])\n",
    "#         sequence_padded = tf.expand_dims(sequence_padded, axis=0)  # Add batch dimension\n",
    "\n",
    "\n",
    "#         y_pred = model([image_feature, sequence_padded], training=False)\n",
    "#         predicted_index = tf.argmax(y_pred, axis=-1)[0]  # Get the token index\n",
    "\n",
    "#         if predicted_index == vectorizer(tf.constant([\"<end>\"]))[0]:  \n",
    "#             break\n",
    "\n",
    "#         caption = caption.write(i, predicted_index)  # Append to TensorArray\n",
    "#         sequence = tf.concat([sequence, [predicted_index]], axis=0)[-15:]  # Update sequence\n",
    "\n",
    "#     vocab = vectorizer.get_vocabulary()\n",
    "#     final_caption = tf.strings.reduce_join(\n",
    "#         tf.convert_to_tensor([vocab[idx] for idx in caption.stack()]), separator=\" \"\n",
    "#     )\n",
    "\n",
    "#     return final_caption\n",
    "\n",
    "# # Call the function with your model and feature inputs\n",
    "# generate_caption(model, extracted_feature, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def predict(model, image_feature, sequence_padded):\n",
    "#     return model([image_feature, sequence_padded], training=False)\n",
    "\n",
    "# predict(model,extracted_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot training history\n",
    "# def plot_training_history():\n",
    "#     \"\"\"Plots loss and accuracy from training history.\"\"\"\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     # Plot Loss\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(train_losses, label='Train Loss')\n",
    "#     plt.plot(val_losses, label='Validation Loss')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title('Training & Validation Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # If accuracy is present in history\n",
    "#     if 'accuracy' in history.history:\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "#         plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Accuracy')\n",
    "#         plt.title('Training & Validation Accuracy')\n",
    "#         plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Call function to plot\n",
    "# plot_training_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mlflow code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\history\\history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# Now you can use loaded_history like history.history\n",
    "print(history.keys())  # Output: dict_keys(['loss', 'val_loss', 'accuracy', 'val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle  # To save the history object\n",
    "\n",
    "# Extract final training and validation loss\n",
    "final_train_loss = history[\"loss\"][-1]\n",
    "final_val_loss = history[\"val_loss\"][-1]\n",
    "\n",
    "# Extract accuracy if available\n",
    "final_train_acc = history.get(\"accuracy\", [None])[-1]\n",
    "final_val_acc = history.get(\"val_accuracy\", [None])[-1]\n",
    "\n",
    "# Log parameters, metrics, and artifacts in MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"epochs\", 10)\n",
    "    mlflow.log_metric(\"train_loss\", final_train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", final_val_loss)\n",
    "\n",
    "    if final_train_acc is not None:\n",
    "        mlflow.log_metric(\"train_accuracy\", final_train_acc)\n",
    "    if final_val_acc is not None:\n",
    "        mlflow.log_metric(\"val_accuracy\", final_val_acc)\n",
    "\n",
    "    # Log artifacts (history and model)\n",
    "    mlflow.log_artifact(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\history\\history.pkl\")\n",
    "    mlflow.log_artifact(r\"U:\\nlp_project\\Image_Sharing_Plateform\\data\\trained_model\\cnn_lstm_model\\trained_model.h5\")\n",
    "\n",
    "print(\"Training metrics and history saved. Run `mlflow ui` to view logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # Ensure model_training_config is assigned before use\n",
    "#     manager = ModelTrainingConfigurationManager(PARAMS_FILE_PATH)\n",
    "#     model_training_config = manager.get_model_training_config()\n",
    "\n",
    "#     train_data_path = model_training_config.train_data_path\n",
    "#     validation_data_path = model_training_config.validation_data_path\n",
    "#     trained_model_path = model_training_config.trained_model_path\n",
    "#     history_path = model_training_config.history_path\n",
    "\n",
    "#     try:\n",
    "#         with open(train_data_path + \"/\" + \"train_data.pkl\", \"rb\") as file:\n",
    "#             train_data = pickle.load(file)\n",
    "\n",
    "#         with open(validation_data_path + \"/\" + \"validation_data.pkl\", \"rb\") as file:\n",
    "#             validation_data = pickle.load(file)\n",
    "\n",
    "#         train_data_features = train_data[\"image_data\"]\n",
    "#         train_caption_tokenized = train_data[\"caption_data\"]\n",
    "\n",
    "#         validation_data_features = validation_data[\"image_data\"]\n",
    "#         validation_caption_tokenized = validation_data[\"caption_data\"]\n",
    "\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(f\"Error while loading dataset: {e}\")\n",
    "\n",
    "#     train_data_generator = ImageCaptionGenerator(\n",
    "#         image_features=train_data_features,\n",
    "#         tokenized_captions=train_caption_tokenized,\n",
    "#         batch_size=8,\n",
    "#         shuffle=True\n",
    "#     )\n",
    "\n",
    "#     validation_data_generator = ImageCaptionGenerator(\n",
    "#         image_features=validation_data_features,\n",
    "#         tokenized_captions=validation_caption_tokenized,\n",
    "#         batch_size=10,\n",
    "#         shuffle=True\n",
    "#     )\n",
    "\n",
    "#     model_training = ModelTraining(\n",
    "#         model_training_config.trained_model_path, \n",
    "#         model_training_config.CreateSqueezeModel_config, \n",
    "#         model_training_config.CreateLSTMSequence_config\n",
    "#     )\n",
    "\n",
    "#     model = model_training.create_image_captioning_model()\n",
    "\n",
    "#     model_training.start_model_training(\n",
    "#         model, \n",
    "#         train_data_generator, \n",
    "#         validation_data_generator\n",
    "#     )\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n",
    "#     raise e  # Rethrow the error for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_per_epoch = len(train_data_generator)\n",
    "# validation_steps = len(validation_data_generator)\n",
    "\n",
    "# # Train the model and store the history\n",
    "# history = model.fit(\n",
    "#     train_data_generator,\n",
    "#     epochs=10,  # Adjust based on your needs\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_data=validation_data_generator,\n",
    "#     validation_steps=validation_steps,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "# epoch = 10\n",
    "# if batch_size is 10, and total data in 90608 then in each each there will be 9060 batch\n",
    "# if epoch ==10 then 9060 batch in each batch i.e whole data will do to training 10 times in 9060 batch and each batch contains 10 datapoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_data_generator:\n",
    "#     (X1_batch, X2_batch), y_batch = batch\n",
    "#     print(f\"X1_batch shape: {X1_batch.shape}\")  # Should be (batch_size, 256)\n",
    "#     print(f\"X2_batch shape: {X2_batch.shape}\")  # Should be (batch_size, 32)\n",
    "#     print(f\"y_batch shape: {y_batch.shape}\")    # Should be (batch_size,)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
